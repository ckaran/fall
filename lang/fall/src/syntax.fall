tokenizer {
  eq '='
  pipe '|'
  star '*'
  question '?'
  dot '.'
  comma ','
  hash '#'
  lbrace '{'
  rbrace '}'
  lbrack '['
  rbrack ']'
  langle '<'
  rangle '>'
  lparen '('
  rparen ')'
  kw_node 'node'
  kw_class 'class'
  kw_tokenizer 'tokenizer'
  kw_rule 'rule'
  kw_verbatim 'verbatim'
  kw_ast 'ast'
  kw_pub 'pub'
  kw_example 'example'

  whitespace r"\s+"
  number r"\d+"
  simple_string r#"'([^'\\]|\\.)*'"#
  hash_string r"r#*" 'parse_raw_string'
  ident r"\w+"
}

pub rule fall_file {
  <rep <with_skip file_form_first file_form>>
}

rule file_form {
  tokenizer_def
| syn_rule
| verbatim_def
| ast_def
| example_def
}

rule file_form_first {
  'tokenizer' | 'pub' | 'rule' | '#' | 'verbatim' | 'ast' | 'example'
}

pub rule tokenizer_def {
  'tokenizer' <commit> '{' <rep lex_rule> '}'
}

pub rule lex_rule { ident <commit> string <opt string> }

pub rule syn_rule {
  <opt attributes> <opt 'pub'> 'rule' <commit>
  ident block_expr
}

pub rule attributes {
    '#' '['
     <rep {attribute { ',' | &']' } }>
     ']'
}

pub rule attribute { 
  ident <opt {'(' number ')'}>
}

pub rule string { simple_string | hash_string }

pub rule verbatim_def { 'verbatim' <commit> hash_string }

pub rule example_def { 'example' <commit> hash_string }

pub rule ast_def { 
  'ast' <commit> '{' 
    <rep <with_skip 
      {'node'|'class'} 
      {ast_node_def | ast_class_def}>> 
  '}' 
}


pub rule ast_node_def {
  'node' <commit> ident '{' <rep method_def> '}'
}

pub rule ast_class_def {
  'class' <commit> ident '{' <layer block_body <rep ident>> '}'
}

pub rule method_def { ident ast_selector }
pub rule ast_selector { ident <opt ast_selector_suffix> }
rule ast_selector_suffix { '?' '.' ident  | '.' ident | '*' | '?' }

rule expr { call_expr | ref_expr | block_expr }
pub rule ref_expr { ident | simple_string }
pub rule call_expr { '<' ident <rep expr> '>' }
pub rule seq_expr { <rep expr> }
pub rule block_expr {
  '{' <layer block_body {<opt seq_expr> <rep {'|' seq_expr}>}> '}'
}

rule block_body { <rep balanced> }
rule balanced {
  '{' <commit> block_body '}'
| <not '}'>
}


verbatim r#########"

fn parse_raw_string(s: &str) -> Option<usize> {
    let quote_start = s.find('"').unwrap();
    let q_hashes = concat!('"', "######", "######", "######", "######", "######");
    let closing = &q_hashes[..quote_start];
    s[quote_start + 1..].find(closing).map(|i| i + quote_start + 1 + closing.len())
}

"#########

ast {
  node fall_file {
    tokenizer_def tokenizer_def?
    syn_rules syn_rule*
    verbatim_def verbatim_def?
    ast_def ast_def?
    examples example_def*
  }

  node tokenizer_def {
    lex_rules lex_rule*
  }

  node lex_rule {
    node_type IDENT.text
  }

  node syn_rule {
    attributes attributes?
    name IDENT?.text
    body expr
  }

  node attributes {
    attributes attribute*
  }

  node attribute {
    name IDENT.text
    value NUMBER?.text
  }

  node verbatim_def { }

  node ast_def {
    ast_nodes ast_node_def*
    ast_classes ast_class_def*
  }

  node ast_node_def {
    name IDENT.text
    methods method_def*
  }

  node ast_class_def {
  }

  node method_def {
    name IDENT.text
  }

  node ref_expr {  }

  node call_expr {
    fn_name IDENT.text
    args expr*
  }

  node seq_expr {
    parts expr*
  }

  node block_expr {
    alts expr*
  }

  class expr {
    ref_expr call_expr seq_expr block_expr
  }

  node example_def { }
}

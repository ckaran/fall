tokenizer {
  #[skip] whitespace r"\s+"
  raw_string r#"r#+""# 'parse_raw_string'
  foo 'foo'
  bar 'bar'
  t1 '_1'
  t2 '_2'
  t3 '_3'
  t4 '_4'
  lbrace '{'
  rbrace '}'
  atom r"\w+"
}

pub rule file {
  '_1' raw_string | '_2' empty atom empty | '_3' private_partial | '_4' block
}

pub rule private_partial {
  foobar | foofoo
}

rule foobar { 'foo' 'bar' }
rule foofoo { 'foo' 'foo' }

pub rule empty { <opt {none}> }

rule none { }

pub rule block {
  '{' <commit> block_body '}'
}

rule block_body { <rep balanced> }
rule balanced {
  '{' <commit> block_body '}'
| {<not '}'> <any>}
}

verbatim r#########"

fn parse_raw_string(s: &str) -> Option<usize> {
    let quote_start = s.find('"').unwrap();
    let q_hashes = concat!('"', "######", "######", "######", "######", "######");
    let closing = &q_hashes[..quote_start];
    s[quote_start + 1..].find(closing).map(|i| i + quote_start + 1 + closing.len())
}

"#########

